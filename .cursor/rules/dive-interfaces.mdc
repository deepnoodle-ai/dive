---
description: 
globs: 
alwaysApply: true
---
# Dive - The AI Toolkit for Go

**Dive** is an open-source framework and CLI for embedding AI-powered agents and automating multi-step workflows in Go. It provides a unified abstraction over LLM-backed chat/work tasks, a declarative workflow engine, a modular tool system, and out-of-the-box integration with major LLM providers. Dive is ideal for researchers, data engineers, and Go developers who want to build autonomous assistants, orchestrate pipelines, or rapidly prototype AI-native applications.

## Purpose

- **Embed** LLM-backed agents into Go applications via a clean interface
- **Automate** research or data-processing pipelines as multi-step, event-driven workflows
- **Customize** by plugging in custom tools, document stores, or LLM providers
- **Interact** using a CLI for running workflows, chatting with agents, or validating configurations

## Key Concepts & Ideas

### Agents

- Encapsulate an LLM chat session plus tools, memory, and work-assignment capabilities
- Expose a common `Agent` interface (`dive/dive.go`) for synchronous or streaming chat
- Support supervisory patterns where a parent agent delegates tasks to subordinates

### Environment

- A runtime container hosting agents, workflows, document repositories, and action handlers
- Implements the `Environment` interface (`environment/environment.go`) to orchestrate tasks, manage state, and emit real-time events

### Workflows

- Declarative YAML definitions of inputs, steps, conditions, and actions
- Config types in `config/types.go`; parsing in `config/parse.go`; builders in `config/build_*.go`
- Workflow execution graph and runner in `workflow/*.go`, enabling conditional branches and parallel steps

### Tools

- Pluggable capabilities agents can invoke mid-completion (e.g., web search, fetch, document read/write)
- Defined using LLM function-calling schemas (`llm/tool.go`); custom tools implement the `llm.Tool` interface
- Built-in tools include `Web.Search`, `Web.Fetch`, `Document.Read`, and `Document.Write`

### LLM Interface

- Abstracts provider details, token counting, streaming, and tool-calling hooks
- Core interfaces in `llm/llm.go`, `llm/options.go`, and `llm/stream.go`
- Concrete providers under `llm/providers/` (Anthropic, OpenAI, Groq)

### Event Streaming

- Agents and workflows emit typed events (`response.created`, `tool_call`, `tool_result`, etc.)
- `ResponseEvent` and `ResponseStream` in `dive/event.go` allow real-time UI updates or pipeline chaining

## Code Organization

```
.
├── README.md              # Project overview, quick-start, examples
├── dive.go                # Core interfaces: Agent, Environment, Options
├── document.go            # Document and repository abstractions
├── event.go               # Event streaming API
├── confirmer.go           # User confirmation helper
├── utilities.go           # Miscellaneous helpers
├── cmd/                   # CLI commands (Cobra-based)
│   └── dive/
│       └── cli/
├── agent/                 # Agent implementations, templates, prompt logic
├── config/                # YAML parsing and builders for agents, workflows
├── environment/           # Runtime orchestration and action handlers
├── workflow/              # Workflow graph, steps, and condition evaluation
├── llm/                   # LLM interface, streaming, and tool hooks
│   └── providers/         # Anthropic, OpenAI, Groq integrations
├── examples/              # Sample workflows and usage snippets
├── fixtures/              # Test fixtures
├── scripts/               # Build and test automation scripts
├── retry/                 # Retry logic utilities
└── slogger/               # Structured logging support
```

## Important Context

- **Testing:** Comprehensive `*_test.go` coverage across parsing, execution, and agent behavior
- **Configuration-First:** Workflows and agents are defined purely in YAML for portability and CI validation
- **Extensibility:** Swap in custom document stores, tools, or LLM providers via Go interfaces
- **Observability:** Streaming events support building dashboards, UIs, or chaining complex pipelines
- **Roadmap Highlights:** Server mode, RAG patterns, cloud integrations (AWS/GCP), voice/embedding support, memory persistence
